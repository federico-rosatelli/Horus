2024-06-27 21:44:36.079 - staging - trainTeacher - WARNING - EPOCH: 1
2024-06-27 21:44:39.184 - staging - trainTeacher - INFO - Min Loss: 0.01290128380060196 at 0
2024-06-27 21:44:44.962 - staging - trainTeacher - INFO - Min Loss: 0.011903279460966587 at 7
2024-06-27 21:47:11.849 - staging - trainTeacher - WARNING - EPOCH: 1
2024-06-27 21:47:12.330 - staging - trainTeacher - INFO - Min Loss: 0.01692119985818863 at 0
2024-06-27 21:47:12.744 - staging - trainTeacher - INFO - Min Loss: 0.014798705466091633 at 1
2024-06-27 21:47:13.527 - staging - trainTeacher - INFO - Min Loss: 0.010974808596074581 at 3
2024-06-27 21:47:26.945 - staging - trainTeacher - INFO - Min Loss: 0.010625213384628296 at 39
2024-06-27 21:47:32.964 - staging - trainTeacher - INFO - Min Loss: 0.00920835044234991 at 54
2024-06-27 21:47:51.804 - staging - trainTeacher - INFO - Mean Loss: 0.01729075574675704 - Mean Batch Loss: 0.01729075574675704. 100 to 74195
2024-06-27 21:47:52.994 - staging - trainTeacher - INFO - Saving batch 100 in model
2024-06-27 21:48:31.501 - staging - trainTeacher - INFO - Mean Loss: 0.01778155044925895 - Mean Batch Loss: 0.018277253098785876. 200 to 74195
2024-06-27 21:49:08.857 - staging - trainTeacher - INFO - Mean Loss: 0.0174229448395116 - Mean Batch Loss: 0.016702147563919426. 300 to 74195
2024-06-27 21:49:09.327 - staging - trainTeacher - INFO - Saving batch 300 in model
2024-06-27 21:49:19.319 - staging - trainTeacher - INFO - Min Loss: 0.00883624516427517 at 326
2024-06-27 21:49:46.605 - staging - trainTeacher - INFO - Mean Loss: 0.017354708308925354 - Mean Batch Loss: 0.01714931635186076. 400 to 74195
2024-06-27 21:50:26.802 - staging - trainTeacher - INFO - Mean Loss: 0.017393269105823693 - Mean Batch Loss: 0.01754789790138602. 500 to 74195
2024-06-27 21:51:05.202 - staging - trainTeacher - INFO - Mean Loss: 0.017334057109588494 - Mean Batch Loss: 0.01703740500845015. 600 to 74195
2024-06-27 21:51:42.949 - staging - trainTeacher - INFO - Mean Loss: 0.017110382432593683 - Mean Batch Loss: 0.015766097623854877. 700 to 74195
2024-06-27 21:51:43.332 - staging - trainTeacher - INFO - Saving batch 700 in model
2024-06-27 21:52:21.155 - staging - trainTeacher - INFO - Mean Loss: 0.01698142731127407 - Mean Batch Loss: 0.016077451910823583. 800 to 74195
2024-06-27 21:52:58.348 - staging - trainTeacher - INFO - Mean Loss: 0.01698376690259784 - Mean Batch Loss: 0.017002507029101253. 900 to 74195
2024-06-27 21:53:35.475 - staging - trainTeacher - INFO - Mean Loss: 0.016955604908855764 - Mean Batch Loss: 0.01670186534523964. 1000 to 74195
2024-06-27 21:54:12.929 - staging - trainTeacher - INFO - Mean Loss: 0.016927715202287637 - Mean Batch Loss: 0.016648539239540697. 1100 to 74195
2024-06-27 21:54:49.592 - staging - trainTeacher - INFO - Mean Loss: 0.016846968915676396 - Mean Batch Loss: 0.015957952300086616. 1200 to 74195
2024-06-27 21:55:27.279 - staging - trainTeacher - INFO - Mean Loss: 0.016796280844688278 - Mean Batch Loss: 0.016187517112120985. 1300 to 74195
2024-06-27 21:55:56.839 - staging - trainTeacher - INFO - Min Loss: 0.008789929561316967 at 1380
2024-06-27 21:56:04.385 - staging - trainTeacher - INFO - Mean Loss: 0.0168140236750979 - Mean Batch Loss: 0.017044857898727058. 1400 to 74195
2024-06-27 21:56:41.532 - staging - trainTeacher - INFO - Mean Loss: 0.016787326390880455 - Mean Batch Loss: 0.01641329743899405. 1500 to 74195
2024-06-27 21:57:18.315 - staging - trainTeacher - INFO - Mean Loss: 0.016767828545529048 - Mean Batch Loss: 0.016475165886804463. 1600 to 74195
2024-06-27 21:57:54.906 - staging - trainTeacher - INFO - Mean Loss: 0.01676714628483708 - Mean Batch Loss: 0.016756223291158678. 1700 to 74195
2024-06-27 21:58:32.350 - staging - trainTeacher - INFO - Mean Loss: 0.016846971885238603 - Mean Batch Loss: 0.018204805348068474. 1800 to 74195
2024-06-27 21:59:09.426 - staging - trainTeacher - INFO - Mean Loss: 0.01681950233576879 - Mean Batch Loss: 0.01632477574981749. 1900 to 74195
2024-06-27 21:59:46.990 - staging - trainTeacher - INFO - Mean Loss: 0.016776622740783613 - Mean Batch Loss: 0.01596148164011538. 2000 to 74195
2024-06-27 22:00:24.526 - staging - trainTeacher - INFO - Mean Loss: 0.01675579205300767 - Mean Batch Loss: 0.016338969990611078. 2100 to 74195
2024-06-27 22:01:01.248 - staging - trainTeacher - INFO - Mean Loss: 0.01674357547413309 - Mean Batch Loss: 0.016486905151978135. 2200 to 74195
2024-06-27 22:01:38.148 - staging - trainTeacher - INFO - Mean Loss: 0.016769734671867993 - Mean Batch Loss: 0.017345498614013195. 2300 to 74195
2024-06-27 22:02:16.382 - staging - trainTeacher - INFO - Mean Loss: 0.016790951172379418 - Mean Batch Loss: 0.01727914284914732. 2400 to 74195
2024-06-27 22:02:49.018 - staging - trainTeacher - INFO - Min Loss: 0.00872416514903307 at 2488
2024-06-27 22:02:53.864 - staging - trainTeacher - INFO - Mean Loss: 0.016799680746403613 - Mean Batch Loss: 0.01700927781872451. 2500 to 74195
2024-06-27 22:03:21.529 - staging - trainTeacher - INFO - Min Loss: 0.008460231125354767 at 2571
2024-06-27 22:03:32.413 - staging - trainTeacher - INFO - Mean Loss: 0.016771204754214637 - Mean Batch Loss: 0.0160590201895684. 2600 to 74195
2024-06-27 22:04:12.213 - staging - trainTeacher - INFO - Mean Loss: 0.016757063895549457 - Mean Batch Loss: 0.016389260161668064. 2700 to 74195
2024-06-27 22:04:50.560 - staging - trainTeacher - INFO - Mean Loss: 0.016757522726292506 - Mean Batch Loss: 0.016769915744662287. 2800 to 74195
2024-06-27 22:05:28.482 - staging - trainTeacher - INFO - Mean Loss: 0.016756308494249385 - Mean Batch Loss: 0.016722297854721548. 2900 to 74195
2024-06-27 22:06:06.180 - staging - trainTeacher - INFO - Mean Loss: 0.01678896440433258 - Mean Batch Loss: 0.017736312355846166. 3000 to 74195
2024-06-27 22:06:45.495 - staging - trainTeacher - INFO - Mean Loss: 0.016808076435204516 - Mean Batch Loss: 0.017381628481671213. 3100 to 74195
2024-06-27 22:07:25.047 - staging - trainTeacher - INFO - Mean Loss: 0.016830358755510325 - Mean Batch Loss: 0.017521333508193494. 3200 to 74195
2024-06-27 22:08:04.845 - staging - trainTeacher - INFO - Mean Loss: 0.0168012555985424 - Mean Batch Loss: 0.015869663543999196. 3300 to 74195
2024-06-27 22:08:44.956 - staging - trainTeacher - INFO - Mean Loss: 0.016794602136639452 - Mean Batch Loss: 0.016574971359223128. 3400 to 74195
2024-06-27 22:09:25.599 - staging - trainTeacher - INFO - Mean Loss: 0.016825485728219285 - Mean Batch Loss: 0.017875836677849293. 3500 to 74195
2024-06-27 22:10:05.229 - staging - trainTeacher - INFO - Mean Loss: 0.01683549996919597 - Mean Batch Loss: 0.01718609854578972. 3600 to 74195
2024-06-27 22:10:46.066 - staging - trainTeacher - INFO - Mean Loss: 0.01684484701785839 - Mean Batch Loss: 0.017181434240192174. 3700 to 74195
2024-06-27 22:11:26.297 - staging - trainTeacher - INFO - Mean Loss: 0.01686336696358636 - Mean Batch Loss: 0.017548790154978632. 3800 to 74195
2024-06-27 22:12:05.985 - staging - trainTeacher - INFO - Mean Loss: 0.016861688011912956 - Mean Batch Loss: 0.016797871058806778. 3900 to 74195
2024-06-27 22:12:45.539 - staging - trainTeacher - INFO - Mean Loss: 0.016834679873922308 - Mean Batch Loss: 0.01578109241090715. 4000 to 74195
2024-06-27 22:13:06.381 - staging - trainTeacher - INFO - Min Loss: 0.00842768419533968 at 4053
2024-06-27 22:13:25.285 - staging - trainTeacher - INFO - Mean Loss: 0.0168321826861991 - Mean Batch Loss: 0.016732270205393432. 4100 to 74195
2024-06-27 22:14:04.602 - staging - trainTeacher - INFO - Mean Loss: 0.016833172898036375 - Mean Batch Loss: 0.01687378148548305. 4200 to 74195
2024-06-27 22:14:43.652 - staging - trainTeacher - INFO - Mean Loss: 0.016847249274431163 - Mean Batch Loss: 0.017438597846776246. 4300 to 74195
2024-06-27 22:15:22.437 - staging - trainTeacher - INFO - Mean Loss: 0.016832318052842493 - Mean Batch Loss: 0.01619012621231377. 4400 to 74195
2024-06-27 22:16:00.894 - staging - trainTeacher - INFO - Mean Loss: 0.016846787776459496 - Mean Batch Loss: 0.01748360031284392. 4500 to 74195
2024-06-27 22:16:40.351 - staging - trainTeacher - INFO - Mean Loss: 0.016855070311385854 - Mean Batch Loss: 0.01722786720842123. 4600 to 74195
2024-06-27 22:17:18.980 - staging - trainTeacher - INFO - Mean Loss: 0.016843724260857524 - Mean Batch Loss: 0.016321692476049067. 4700 to 74195
2024-06-27 22:17:56.802 - staging - trainTeacher - INFO - Mean Loss: 0.01684092337289277 - Mean Batch Loss: 0.016709253629669546. 4800 to 74195
2024-06-27 22:18:35.336 - staging - trainTeacher - INFO - Mean Loss: 0.01683519626067831 - Mean Batch Loss: 0.016560237603262067. 4900 to 74195
2024-06-27 22:19:12.947 - staging - trainTeacher - INFO - Mean Loss: 0.016835662606158295 - Mean Batch Loss: 0.016858518198132513. 5000 to 74195
2024-06-27 22:19:51.743 - staging - trainTeacher - INFO - Mean Loss: 0.016851623736868195 - Mean Batch Loss: 0.01764983988367021. 5100 to 74195
2024-06-27 22:20:29.342 - staging - trainTeacher - INFO - Mean Loss: 0.016862786511971706 - Mean Batch Loss: 0.017432199670001865. 5200 to 74195
2024-06-27 22:21:09.299 - staging - trainTeacher - INFO - Mean Loss: 0.016851614246598517 - Mean Batch Loss: 0.016270544724538923. 5300 to 74195
2024-06-27 22:21:47.615 - staging - trainTeacher - INFO - Mean Loss: 0.016853342954275607 - Mean Batch Loss: 0.016944981748238205. 5400 to 74195
2024-06-27 22:22:25.229 - staging - trainTeacher - INFO - Mean Loss: 0.016861847023669427 - Mean Batch Loss: 0.017321151811629534. 5500 to 74195
2024-06-27 22:23:04.075 - staging - trainTeacher - INFO - Mean Loss: 0.016860010431455227 - Mean Batch Loss: 0.016758979493752123. 5600 to 74195
2024-06-27 22:23:43.154 - staging - trainTeacher - INFO - Mean Loss: 0.016860182526122945 - Mean Batch Loss: 0.016869821548461915. 5700 to 74195
2024-06-27 22:24:22.998 - staging - trainTeacher - INFO - Mean Loss: 0.0168501320414642 - Mean Batch Loss: 0.016277153911069035. 5800 to 74195
2024-06-27 22:25:02.925 - staging - trainTeacher - INFO - Mean Loss: 0.016842070752159807 - Mean Batch Loss: 0.016374435359612107. 5900 to 74195
2024-06-27 22:25:42.105 - staging - trainTeacher - INFO - Mean Loss: 0.016856115957769556 - Mean Batch Loss: 0.01768492354080081. 6000 to 74195
2024-06-27 22:26:25.619 - staging - trainTeacher - INFO - Mean Loss: 0.01685499147919749 - Mean Batch Loss: 0.016787511520087717. 6100 to 74195
2024-06-27 22:27:05.833 - staging - trainTeacher - INFO - Mean Loss: 0.01683218155396867 - Mean Batch Loss: 0.015440548015758395. 6200 to 74195
2024-06-27 22:27:06.769 - staging - trainTeacher - INFO - Saving batch 6200 in model
2024-06-27 22:27:45.371 - staging - trainTeacher - INFO - Mean Loss: 0.01682945845760683 - Mean Batch Loss: 0.016660599252209068. 6300 to 74195
2024-06-27 22:28:25.174 - staging - trainTeacher - INFO - Mean Loss: 0.016824964648224687 - Mean Batch Loss: 0.016541809719055892. 6400 to 74195
2024-06-27 22:29:04.002 - staging - trainTeacher - INFO - Mean Loss: 0.016823687534931166 - Mean Batch Loss: 0.01674193951301277. 6500 to 74195
2024-06-27 22:29:43.425 - staging - trainTeacher - INFO - Mean Loss: 0.016826653404962998 - Mean Batch Loss: 0.017019464615732432. 6600 to 74195
2024-06-27 22:32:17.936 - staging - trainTeacher - WARNING - EPOCH: 1
2024-06-27 22:32:19.672 - staging - trainTeacher - INFO - Min Loss: 0.014772359281778336 at 0
2024-06-27 22:32:19.843 - staging - arguments_parser - CRITICAL - Interrupt by User | 
2024-06-27 22:43:03.919 - staging - trainTeacher - WARNING - EPOCH: 1
2024-06-27 22:43:04.311 - staging - trainTeacher - INFO - Min Loss: 0.020609606057405472 at 0
2024-06-27 22:43:04.686 - staging - trainTeacher - INFO - Min Loss: 0.014832633547484875 at 1
2024-06-27 22:43:04.994 - staging - main - CRITICAL - Interrupt by User
2024-06-27 22:43:04.995 - staging - main - CRITICAL - Total Time: 1.148507833480835
2024-06-27 22:43:59.245 - staging - trainTeacher - WARNING - EPOCH: 1
2024-06-27 22:43:59.653 - staging - trainTeacher - INFO - Min Loss: 0.013509481213986874 at 0
2024-06-27 22:44:00.009 - staging - main - CRITICAL - Interrupt by User - Total Time: 0.8369145393371582s
2024-06-27 22:45:52.937 - staging - trainTeacher - WARNING - EPOCH: 1
2024-06-27 22:45:53.337 - staging - trainTeacher - INFO - Min Loss: 0.024324465543031693 at 0
2024-06-27 22:45:53.921 - staging - main - CRITICAL - Interrupt by User - Total Time: 1.06 s
